## 爬虫

### 介绍

* 编写的模拟浏览器行为的客户端程序，简单粗暴将服务器返回的所有数据获取下来，不做任何处理和筛选
* 模拟浏览器发送请求，获得和浏览器一模一样的数据
* 就是自动抓取网页信息的代码，可以简单理解为代替繁琐的复制粘贴操作的手段
* 爬虫必须是已经看到的网站

### 定义

* 网页蜘蛛，网络机器人，按照一定规则自动抓取万维网信息的程序
* 进行数据分析，得出结论

### 分类

* 通用爬虫
    * 搜索引擎的爬虫
* 聚焦爬虫
    * 针对特定网站的爬虫

## 基本步骤

### 介绍

```js
明确 URL ，请求的地址，明确爬取什么
发送请求，获取响应数据
保存响应数据， 提取有效信息
数据处理， 存储使用
```



### 分析需求

```js
确定需要的东西是什么
chrome 审查元素 查看网页源代码
```



### 获取网页源代码

```js
// 介绍
	你输入一个 url , 服务器后端会把网页源代码传送过来，给到浏览器进行渲染，
	我们要做的就是把这个网页源代码复制过来 ， 然后对网页源代码进行解析(提取页面上我们需要的信息)

// 进行 请求 post  get
    1. 使用原生库 net/http 进行请求即可
    2. 使用别人封装好的库 ：gorequest
        文档 ：https://github.com/parnurzeal/gorequest
// 请求头
	Uer-Agent
```

### 解析网页

```js
介绍
	网站有源代码发过来，你需要操作网页元素进行操作，提取出来你要的东西
    你要的东西 : 就是在页面上你看到的数据什么的，这些镶嵌到网页元素中或者请求中，你需要提亮出来

// 网页响应
// 对获取的网页源代码，进一步解析，得到我们想要的数据
html 格式		
	正则表达式、Css选择器
json
	用 原生库 encoding/json 对得到的数据进行反序泪花
Xml
	不常用
    
网页解析库
	bs4 lxml pyquery
```

### 数据处理

```js
// 将得到的数据存入数据库
本地
	text
    json 
    csv
    db
数据库
	关系型
    非关系型
    搜索引擎
```

## 其他

*   代理 ip 池
*   User-Agent 模拟浏览器
*   APP
    *   抓包工具

## 难点

*   分布式
*   大规模抓取



## 解析网页

